import Anthropic from '@anthropic-ai/sdk';
import { env } from '../../../config/env';
import { BaseAIProvider, AIResponseWithMetadata } from './base-ai-provider';

// –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏—è
interface AIResponseWithCachingMetadata extends AIResponseWithMetadata {
  metadata: AIResponseWithMetadata['metadata'] & {
    caching?: {
      enabled: boolean;
      ttl?: '5min';
      structured?: boolean;
      cacheCreationTokens?: number;
      cacheReadTokens?: number;
      cacheCost?: number;
    };
  };
}

export class AnthropicProvider extends BaseAIProvider {
  private anthropic: Anthropic;

  constructor() {
    super();
    
    if (!env.ANTHROPIC_API_KEY || env.ANTHROPIC_API_KEY.trim() === '') {
      throw new Error('ANTHROPIC_API_KEY –Ω–µ –∑–∞–¥–∞–Ω –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è. –î–æ–±–∞–≤—å—Ç–µ –µ–≥–æ –≤ .env.development —Ñ–∞–π–ª –∏–ª–∏ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –æ–∫—Ä—É–∂–µ–Ω–∏—è.');
    }
    
    this.anthropic = new Anthropic({
      apiKey: env.ANTHROPIC_API_KEY,
    });
  }

  protected async callAI(systemPrompt: string, userPrompt: string, temperature: number): Promise<string> {
    const response = await this.callAIWithMetadata(systemPrompt, userPrompt, temperature);
    return response.content;
  }

  /**
   * –í—ã–∑–æ–≤ AI —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏ –∏ 5-–º–∏–Ω—É—Ç–Ω—ã–º –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º (–≤–∫–ª—é—á–µ–Ω–æ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)
   * @param systemPrompt - —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç
   * @param userPrompt - –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –ø—Ä–æ–º–ø—Ç  
   * @param temperature - —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
   * @param options - –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –æ–ø—Ü–∏–∏
   * @param options.enableCaching - –≤–∫–ª—é—á–∏—Ç—å 5-–º–∏–Ω—É—Ç–Ω–æ–µ –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é true)
   */
  protected async callAIWithMetadata(
    systemPrompt: string, 
    userPrompt: string, 
    temperature: number,
    options?: {
      model?: string;
      maxTokens?: number;
      temperature?: number;
      enableCaching?: boolean;
    }
  ): Promise<AIResponseWithCachingMetadata> {
    const maxTokens = options?.maxTokens || 4000;
    const model = options?.model || "claude-sonnet-4-20250514";
    const finalTemperature = options?.temperature ?? temperature;
    const enableCaching = options?.enableCaching ?? true; // 5-–º–∏–Ω—É—Ç–Ω–æ–µ –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ –≤–∫–ª—é—á–µ–Ω–æ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é

    console.log('üîç SYSTEM PROMPT LENGTH:', systemPrompt.length, 'chars');
    console.log('üîç USER PROMPT LENGTH:', userPrompt.length, 'chars');

    console.log('üîç CACHING ENABLED:', enableCaching);
    console.log('üîç MODEL:', model);
    
    // –ü—Ä–æ–≤–µ—Ä–∫–∞ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞ –¥–ª—è –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏—è (1024 —Ç–æ–∫–µ–Ω–∞ –¥–ª—è Sonnet)
    const systemPromptTokens = Math.ceil(systemPrompt.length / 4);
    
    // –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ—Ç–∫–ª—é—á–∞–µ–º –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è –∫–æ—Ä–æ—Ç–∫–∏—Ö –ø—Ä–æ–º–ø—Ç–æ–≤
    let actuallyEnableCaching = enableCaching;
    if (enableCaching && systemPromptTokens < 1024) {
      console.log('‚ö†Ô∏è  WARNING: System prompt too short for caching (need 1024+ tokens, estimated:', systemPromptTokens, ')');
      console.log('üìä CACHE REQUIREMENTS: System prompt must be ‚â•1024 tokens for ' + model);
      console.log('üîÑ Automatically disabling caching for this request');
      actuallyEnableCaching = false;
    } else if (enableCaching) {
      console.log('‚úÖ System prompt size OK for caching, estimated tokens:', systemPromptTokens);
    }

    // –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º system –ø—Ä–æ–º–ø—Ç —Å —É—á–µ—Ç–æ–º –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏—è
    let systemMessages: any;
    if (actuallyEnableCaching) {
      systemMessages = [
        {
          type: "text" as const,
          text: systemPrompt,
          cache_control: { 
            type: "ephemeral" as const // 5-–º–∏–Ω—É—Ç–Ω–æ–µ –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ (–µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω—ã–π –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ç–∏–ø)
          }
        }
      ];
      // console.log('üîç SYSTEM MESSAGES WITH CACHING:', JSON.stringify(systemMessages, null, 2));
    } else {
      systemMessages = systemPrompt;
      // console.log('üîç SYSTEM MESSAGES WITHOUT CACHING:', systemMessages);
    }

    const message = await this.anthropic.messages.create({
      model,
      max_tokens: maxTokens,
      temperature: finalTemperature,
      system: systemMessages,
      messages: [
        {
          role: "user",
          content: userPrompt
        }
      ]
    });

    // console.log('üîç MESSAGE:', message);

    const content = message.content[0];
    if (content.type !== 'text' || !content.text) {
      throw new Error('–ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –æ—Ç Anthropic');
    }

    // –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏ —Ç–æ–∫–µ–Ω–æ–≤
    const usage = message.usage;
    console.log('üîç FULL USAGE OBJECT:', JSON.stringify(usage, null, 2));
    
    const promptTokens = usage.input_tokens;
    const completionTokens = usage.output_tokens;
    const cacheCreationTokens = (usage as any).cache_creation_input_tokens || 0;
    const cacheReadTokens = (usage as any).cache_read_input_tokens || 0;
    const actualTotalTokens = promptTokens + completionTokens;
    
    console.log('üîç CACHE TOKENS EXTRACTED:');
    console.log('  - cache_creation_input_tokens:', cacheCreationTokens);
    console.log('  - cache_read_input_tokens:', cacheReadTokens);

    // –õ–æ–≥–∏—Ä—É–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏–∏
    if (actuallyEnableCaching) {
      console.log('üì¶ CACHE INFO:');
      console.log('  Cache creation tokens:', cacheCreationTokens);
      console.log('  Cache read tokens:', cacheReadTokens);
      console.log('  Regular input tokens:', promptTokens);
    }

    // –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º —Å—Ç–æ–∏–º–æ—Å—Ç—å —Å —É—á–µ—Ç–æ–º –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏—è (–¥–ª—è Claude-3.5-Sonnet)
    // Base rates: Input: $3.00 / 1M tokens, Output: $15.00 / 1M tokens
    // Cache writes: 1.25x base rate, Cache reads: 0.1x base rate
    const baseInputRate = 3.00;
    const outputRate = 15.00;
    
    let inputCost = (promptTokens / 1000000) * baseInputRate;
    let cacheCost = 0;
    
    if (actuallyEnableCaching) {
      const cacheWriteRate = baseInputRate * 1.25; // 5-–º–∏–Ω—É—Ç–Ω—ã–π –∫–µ—à: +25%
      const cacheReadRate = baseInputRate * 0.1;   // –ß—Ç–µ–Ω–∏–µ –∫–µ—à–∞: 10%
      
      cacheCost = (cacheCreationTokens / 1000000) * cacheWriteRate + 
                  (cacheReadTokens / 1000000) * cacheReadRate;
    }
    
    const outputCost = (completionTokens / 1000000) * outputRate;
    const totalCost = inputCost + cacheCost + outputCost;

    return {
      content: content.text,
      metadata: {
        provider: 'anthropic',
        model,
        prompt: userPrompt,
        context: systemPrompt,
        fullResponse: content.text,
        tokensUsed: actualTotalTokens,
        promptTokens,
        completionTokens,
        cost: totalCost,
        temperature: finalTemperature,
        maxTokens,
        responseTime: 0, // –ë—É–¥–µ—Ç —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ –≤ –±–∞–∑–æ–≤–æ–º –∫–ª–∞—Å—Å–µ
        generatedAt: new Date().toISOString(),
        // –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏–∏
        caching: actuallyEnableCaching ? {
          enabled: true,
          ttl: '5min',
          cacheCreationTokens,
          cacheReadTokens,
          cacheCost
        } : { enabled: false }
      }
    };
  }

  /**
   * –í—ã–∑–æ–≤ AI —Å 5-–º–∏–Ω—É—Ç–Ω—ã–º –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º –ø—Ä–æ–º–ø—Ç–∞
   * @param systemPrompt - —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏—è
   * @param userPrompt - –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –ø—Ä–æ–º–ø—Ç
   * @param temperature - —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
   */
  public async callWithCaching(
    systemPrompt: string, 
    userPrompt: string, 
    temperature: number = 0.7
  ): Promise<AIResponseWithCachingMetadata> {
    return this.callAIWithMetadata(systemPrompt, userPrompt, temperature, {
      enableCaching: true
    });
  }

  /**
   * –°–æ–∑–¥–∞–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞ —Å –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ —Ç–æ—á–∫–∞–º–∏ –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏—è
   * @param staticInstructions - —Å—Ç–∞—Ç–∏—á–µ—Å–∫–∏–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ (–∫–µ—à–∏—Ä—É—é—Ç—Å—è)
   * @param contextData - –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (–∫–µ—à–∏—Ä—É—é—Ç—Å—è)
   * @param userPrompt - –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –ø—Ä–æ–º–ø—Ç (–Ω–µ –∫–µ—à–∏—Ä—É–µ—Ç—Å—è)
   * @param temperature - —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
   * @param options - –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –æ–ø—Ü–∏–∏
   */
  public async callWithStructuredCaching(
    staticInstructions: string,
    contextData: string,
    userPrompt: string,
    temperature: number = 0.7,
    options?: {
      model?: string;
      maxTokens?: number;
    }
  ): Promise<AIResponseWithCachingMetadata> {
    const model = options?.model || "claude-sonnet-4-20250514";
    const maxTokens = options?.maxTokens || 4000;

    console.log('üîç STRUCTURED CACHING - Static Instructions:', staticInstructions);
    console.log('üîç STRUCTURED CACHING - Context Data:', contextData);
    // console.log('üîç STRUCTURED CACHING - User Prompt:', userPrompt);

    // –°–æ–∑–¥–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π system –ø—Ä–æ–º–ø—Ç —Å –¥–≤—É–º—è —Ç–æ—á–∫–∞–º–∏ –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏—è
    const systemMessages = [
      {
        type: "text" as const,
        text: staticInstructions,
        cache_control: { 
          type: "ephemeral" as const // 5-–º–∏–Ω—É—Ç–Ω–æ–µ –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ (–µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω—ã–π –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ç–∏–ø)
        }
      },
      {
        type: "text" as const, 
        text: contextData,
        cache_control: { 
          type: "ephemeral" as const // 5-–º–∏–Ω—É—Ç–Ω–æ–µ –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ (–µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω—ã–π –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ç–∏–ø)
        }
      }
    ];

    const message = await this.anthropic.messages.create({
      model,
      max_tokens: maxTokens,
      temperature,
      system: systemMessages,
      messages: [
        {
          role: "user",
          content: userPrompt
        }
      ]
    });

    // console.log('üîç STRUCTURED MESSAGE:', message);

    const content = message.content[0];
    if (content.type !== 'text' || !content.text) {
      throw new Error('–ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –æ—Ç Anthropic');
    }

    // –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Ç–≤–µ—Ç–∞ –∞–Ω–∞–ª–æ–≥–∏—á–Ω–æ –æ—Å–Ω–æ–≤–Ω–æ–º—É –º–µ—Ç–æ–¥—É
    const usage = message.usage;
    console.log('üîç STRUCTURED FULL USAGE OBJECT:', JSON.stringify(usage, null, 2));
    
    const promptTokens = usage.input_tokens;
    const completionTokens = usage.output_tokens;
    const cacheCreationTokens = (usage as any).cache_creation_input_tokens || 0;
    const cacheReadTokens = (usage as any).cache_read_input_tokens || 0;
    const actualTotalTokens = promptTokens + completionTokens;

    console.log('üì¶ STRUCTURED CACHE INFO:');
    console.log('  Cache creation tokens:', cacheCreationTokens);
    console.log('  Cache read tokens:', cacheReadTokens);
    console.log('  Regular input tokens:', promptTokens);

    // –†–∞—Å—á–µ—Ç —Å—Ç–æ–∏–º–æ—Å—Ç–∏
    const baseInputRate = 3.00;
    const outputRate = 15.00;
    
    let inputCost = (promptTokens / 1000000) * baseInputRate;
    const cacheWriteRate = baseInputRate * 1.25; // 5-–º–∏–Ω—É—Ç–Ω—ã–π –∫–µ—à: +25%
    const cacheReadRate = baseInputRate * 0.1;   // –ß—Ç–µ–Ω–∏–µ –∫–µ—à–∞: 10%
    
    const cacheCost = (cacheCreationTokens / 1000000) * cacheWriteRate + 
                      (cacheReadTokens / 1000000) * cacheReadRate;
    const outputCost = (completionTokens / 1000000) * outputRate;
    const totalCost = inputCost + cacheCost + outputCost;

    return {
      content: content.text,
      metadata: {
        provider: 'anthropic',
        model,
        prompt: userPrompt,
        context: `${staticInstructions}\n\n${contextData}`,
        fullResponse: content.text,
        tokensUsed: actualTotalTokens,
        promptTokens,
        completionTokens,
        cost: totalCost,
        temperature,
        maxTokens,
        responseTime: 0,
        generatedAt: new Date().toISOString(),
        caching: {
          enabled: true,
          ttl: '5min',
          structured: true,
          cacheCreationTokens,
          cacheReadTokens,
          cacheCost
        }
      }
    };
  }

  protected getProviderName(): string {
    return 'Anthropic';
  }
} 